diff --git a/src/compiler/s390/OWNERS b/src/compiler/s390/OWNERS
index beecb3d..a04d29a 100644
--- a/src/compiler/s390/OWNERS
+++ b/src/compiler/s390/OWNERS
@@ -1,3 +1,4 @@
+dstence@us.ibm.com
 joransiu@ca.ibm.com
 mbrandy@us.ibm.com
 michael_dawson@ca.ibm.com
diff --git a/src/compiler/s390/code-generator-s390.cc b/src/compiler/s390/code-generator-s390.cc
index c619833..bdebd30 100644
--- a/src/compiler/s390/code-generator-s390.cc
+++ b/src/compiler/s390/code-generator-s390.cc
@@ -21,7 +21,7 @@ namespace compiler {
 
 
 // Adds S390-specific methods to convert InstructionOperands.
-class S390OperandConverter FINAL : public InstructionOperandConverter {
+class S390OperandConverter final : public InstructionOperandConverter {
  public:
   S390OperandConverter(CodeGenerator* gen, Instruction* instr)
       : InstructionOperandConverter(gen, instr) {}
@@ -103,7 +103,8 @@ class S390OperandConverter FINAL : public InstructionOperandConverter {
     DCHECK(!op->IsDoubleRegister());
     DCHECK(op->IsStackSlot() || op->IsDoubleStackSlot());
     // The linkage computes where all spill slots are located.
-    FrameOffset offset = linkage()->GetFrameOffset(op->index(), frame(), 0);
+    FrameOffset offset = linkage()->GetFrameOffset(
+        AllocatedOperand::cast(op)->index(), frame(), 0);
     return MemOperand(offset.from_stack_pointer() ? sp : fp, offset.offset());
   }
 };
@@ -116,12 +117,12 @@ static inline bool HasRegisterInput(Instruction* instr, size_t index) {
 
 namespace {
 
-class OutOfLineLoadNAN32 FINAL : public OutOfLineCode {
+class OutOfLineLoadNAN32 final : public OutOfLineCode {
  public:
   OutOfLineLoadNAN32(CodeGenerator* gen, DoubleRegister result)
       : OutOfLineCode(gen), result_(result) {}
 
-  void Generate() FINAL {
+  void Generate() final {
     __ LoadDoubleLiteral(result_, std::numeric_limits<float>::quiet_NaN(),
                          kScratchReg);
   }
@@ -131,12 +132,12 @@ class OutOfLineLoadNAN32 FINAL : public OutOfLineCode {
 };
 
 
-class OutOfLineLoadNAN64 FINAL : public OutOfLineCode {
+class OutOfLineLoadNAN64 final : public OutOfLineCode {
  public:
   OutOfLineLoadNAN64(CodeGenerator* gen, DoubleRegister result)
       : OutOfLineCode(gen), result_(result) {}
 
-  void Generate() FINAL {
+  void Generate() final {
     __ LoadDoubleLiteral(result_, std::numeric_limits<double>::quiet_NaN(),
                          kScratchReg);
   }
@@ -146,12 +147,12 @@ class OutOfLineLoadNAN64 FINAL : public OutOfLineCode {
 };
 
 
-class OutOfLineLoadZero FINAL : public OutOfLineCode {
+class OutOfLineLoadZero final : public OutOfLineCode {
  public:
   OutOfLineLoadZero(CodeGenerator* gen, Register result)
       : OutOfLineCode(gen), result_(result) {}
 
-  void Generate() FINAL { __ li(result_, Operand::Zero()); }
+  void Generate() final { __ li(result_, Operand::Zero()); }
 
  private:
   Register const result_;
@@ -383,16 +384,32 @@ Condition FlagsConditionToCondition(FlagsCondition condition) {
   } while (0)
 
 
-#define ASSEMBLE_STORE_FLOAT(asm_instr, asm_instrx)      \
+#define ASSEMBLE_STORE_FLOAT32()                         \
   do {                                                   \
     size_t index = 0;                                    \
     AddressingMode mode = kMode_None;                    \
     MemOperand operand = i.MemoryOperand(&mode, &index); \
     DoubleRegister value = i.InputDoubleRegister(index); \
+    __ frsp(kScratchDoubleReg, value);                   \
     if (mode == kMode_MRI) {                             \
-      __ asm_instr(value, operand);                      \
+      __ stfs(kScratchDoubleReg, operand);               \
     } else {                                             \
-      __ asm_instrx(value, operand);                     \
+      __ stfsx(kScratchDoubleReg, operand);              \
+    }                                                    \
+    DCHECK_EQ(LeaveRC, i.OutputRCBit());                 \
+  } while (0)
+
+
+#define ASSEMBLE_STORE_DOUBLE()                          \
+  do {                                                   \
+    size_t index = 0;                                    \
+    AddressingMode mode = kMode_None;                    \
+    MemOperand operand = i.MemoryOperand(&mode, &index); \
+    DoubleRegister value = i.InputDoubleRegister(index); \
+    if (mode == kMode_MRI) {                             \
+      __ stfd(value, operand);                           \
+    } else {                                             \
+      __ stfdx(value, operand);                          \
     }                                                    \
     DCHECK_EQ(LeaveRC, i.OutputRCBit());                 \
   } while (0)
@@ -468,29 +485,57 @@ Condition FlagsConditionToCondition(FlagsCondition condition) {
 
 
 // TODO(mbrandy): fix paths that produce garbage in offset's upper 32-bits.
-#define ASSEMBLE_CHECKED_STORE_FLOAT(asm_instr, asm_instrx) \
-  do {                                                      \
-    Label done;                                             \
-    size_t index = 0;                                       \
-    AddressingMode mode = kMode_None;                       \
-    MemOperand operand = i.MemoryOperand(&mode, index);     \
-    DCHECK_EQ(kMode_MRR, mode);                             \
-    Register offset = operand.rb();                         \
-    __ extsw(offset, offset);                               \
-    if (HasRegisterInput(instr, 2)) {                       \
-      __ cmplw(offset, i.InputRegister(2));                 \
-    } else {                                                \
-      __ cmplwi(offset, i.InputImmediate(2));               \
-    }                                                       \
-    __ bge(&done);                                          \
-    DoubleRegister value = i.InputDoubleRegister(3);        \
-    if (mode == kMode_MRI) {                                \
-      __ asm_instr(value, operand);                         \
-    } else {                                                \
-      __ asm_instrx(value, operand);                        \
-    }                                                       \
-    __ bind(&done);                                         \
-    DCHECK_EQ(LeaveRC, i.OutputRCBit());                    \
+#define ASSEMBLE_CHECKED_STORE_FLOAT32()                \
+  do {                                                  \
+    Label done;                                         \
+    size_t index = 0;                                   \
+    AddressingMode mode = kMode_None;                   \
+    MemOperand operand = i.MemoryOperand(&mode, index); \
+    DCHECK_EQ(kMode_MRR, mode);                         \
+    Register offset = operand.rb();                     \
+    __ extsw(offset, offset);                           \
+    if (HasRegisterInput(instr, 2)) {                   \
+      __ cmplw(offset, i.InputRegister(2));             \
+    } else {                                            \
+      __ cmplwi(offset, i.InputImmediate(2));           \
+    }                                                   \
+    __ bge(&done);                                      \
+    DoubleRegister value = i.InputDoubleRegister(3);    \
+    __ frsp(kScratchDoubleReg, value);                  \
+    if (mode == kMode_MRI) {                            \
+      __ stfs(kScratchDoubleReg, operand);              \
+    } else {                                            \
+      __ stfsx(kScratchDoubleReg, operand);             \
+    }                                                   \
+    __ bind(&done);                                     \
+    DCHECK_EQ(LeaveRC, i.OutputRCBit());                \
+  } while (0)
+
+
+// TODO(mbrandy): fix paths that produce garbage in offset's upper 32-bits.
+#define ASSEMBLE_CHECKED_STORE_DOUBLE()                 \
+  do {                                                  \
+    Label done;                                         \
+    size_t index = 0;                                   \
+    AddressingMode mode = kMode_None;                   \
+    MemOperand operand = i.MemoryOperand(&mode, index); \
+    DCHECK_EQ(kMode_MRR, mode);                         \
+    Register offset = operand.rb();                     \
+    __ extsw(offset, offset);                           \
+    if (HasRegisterInput(instr, 2)) {                   \
+      __ cmplw(offset, i.InputRegister(2));             \
+    } else {                                            \
+      __ cmplwi(offset, i.InputImmediate(2));           \
+    }                                                   \
+    __ bge(&done);                                      \
+    DoubleRegister value = i.InputDoubleRegister(3);    \
+    if (mode == kMode_MRI) {                            \
+      __ stfd(value, operand);                          \
+    } else {                                            \
+      __ stfdx(value, operand);                         \
+    }                                                   \
+    __ bind(&done);                                     \
+    DCHECK_EQ(LeaveRC, i.OutputRCBit());                \
   } while (0)
 
 
@@ -536,6 +581,18 @@ Condition FlagsConditionToCondition(FlagsCondition condition) {
   } while (0)
 
 
+void CodeGenerator::AssembleDeconstructActivationRecord() {
+  CallDescriptor* descriptor = linkage()->GetIncomingDescriptor();
+  int stack_slots = frame()->GetSpillSlotCount();
+  if (descriptor->IsJSFunctionCall() || stack_slots > 0) {
+    int pop_count = descriptor->IsJSFunctionCall()
+                        ? static_cast<int>(descriptor->JSParameterCount())
+                        : 0;
+    __ LeaveFrame(StackFrame::MANUAL, pop_count * kPointerSize);
+  }
+}
+
+
 // Assembles an instruction after register allocation, producing machine code.
 void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
   S390OperandConverter i(this, instr);
@@ -556,6 +613,19 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
     }
+    case kArchTailCallCodeObject: {
+      AssembleDeconstructActivationRecord();
+      if (HasRegisterInput(instr, 0)) {
+        __ addi(ip, i.InputRegister(0),
+                Operand(Code::kHeaderSize - kHeapObjectTag));
+        __ Jump(ip);
+      } else {
+        __ Jump(Handle<Code>::cast(i.InputHeapObject(0)),
+                RelocInfo::CODE_TARGET);
+      }
+      DCHECK_EQ(LeaveRC, i.OutputRCBit());
+      break;
+    }
     case kArchCallJSFunction: {
       EnsureSpaceForLazyDeopt();
       Register func = i.InputRegister(0);
@@ -572,6 +642,21 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
     }
+    case kArchTailCallJSFunction: {
+      Register func = i.InputRegister(0);
+      if (FLAG_debug_code) {
+        // Check the function's context matches the context argument.
+        __ LoadP(kScratchReg,
+                 FieldMemOperand(func, JSFunction::kContextOffset));
+        __ cmp(cp, kScratchReg);
+        __ Assert(eq, kWrongFunctionContext);
+      }
+      AssembleDeconstructActivationRecord();
+      __ LoadP(ip, FieldMemOperand(func, JSFunction::kCodeEntryOffset));
+      __ Jump(ip);
+      DCHECK_EQ(LeaveRC, i.OutputRCBit());
+      break;
+    }
     case kArchJmp:
       AssembleArchJump(i.InputRpo(0));
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
@@ -607,8 +692,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       __ TruncateDoubleToI(i.OutputRegister(), i.InputDoubleRegister(0));
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_And32:
-    case kS390_And64:
+    case kS390_And:
       if (HasRegisterInput(instr, 1)) {
         __ and_(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
                 i.OutputRCBit());
@@ -616,13 +700,11 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
         __ andi(i.OutputRegister(), i.InputRegister(0), i.InputImmediate(1));
       }
       break;
-    case kS390_AndComplement32:
-    case kS390_AndComplement64:
+    case kS390_AndComplement:
       __ andc(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
               i.OutputRCBit());
       break;
-    case kS390_Or32:
-    case kS390_Or64:
+    case kS390_Or:
       if (HasRegisterInput(instr, 1)) {
         __ orx(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
                i.OutputRCBit());
@@ -631,13 +713,11 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
         DCHECK_EQ(LeaveRC, i.OutputRCBit());
       }
       break;
-    case kS390_OrComplement32:
-    case kS390_OrComplement64:
+    case kS390_OrComplement:
       __ orc(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
              i.OutputRCBit());
       break;
-    case kS390_Xor32:
-    case kS390_Xor64:
+    case kS390_Xor:
       if (HasRegisterInput(instr, 1)) {
         __ xor_(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
                 i.OutputRCBit());
@@ -692,8 +772,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       }
       break;
 #endif
-    case kS390_Not32:
-    case kS390_Not64:
+    case kS390_Not:
       __ notx(i.OutputRegister(), i.InputRegister(0), i.OutputRCBit());
       break;
     case kS390_RotLeftAndMask32:
@@ -714,8 +793,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
                 63 - i.InputInt32(2), i.OutputRCBit());
       break;
 #endif
-    case kS390_Add32:
-    case kS390_Add64:
+    case kS390_Add:
       if (HasRegisterInput(instr, 1)) {
         __ add(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
                LeaveOE, i.OutputRCBit());
@@ -727,11 +805,10 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
     case kS390_AddWithOverflow32:
       ASSEMBLE_ADD_WITH_OVERFLOW();
       break;
-    case kS390_AddFloat64:
+    case kS390_AddDouble:
       ASSEMBLE_FLOAT_BINOP_RC(fadd);
       break;
-    case kS390_Sub32:
-    case kS390_Sub64:
+    case kS390_Sub:
       if (HasRegisterInput(instr, 1)) {
         __ sub(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
                LeaveOE, i.OutputRCBit());
@@ -743,7 +820,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
     case kS390_SubWithOverflow32:
       ASSEMBLE_SUB_WITH_OVERFLOW();
       break;
-    case kS390_SubFloat64:
+    case kS390_SubDouble:
       ASSEMBLE_FLOAT_BINOP_RC(fsub);
       break;
     case kS390_Mul32:
@@ -764,7 +841,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       __ mulhwu(i.OutputRegister(), i.InputRegister(0), i.InputRegister(1),
                 i.OutputRCBit());
       break;
-    case kS390_MulFloat64:
+    case kS390_MulDouble:
       ASSEMBLE_FLOAT_BINOP_RC(fmul);
       break;
     case kS390_Div32:
@@ -787,7 +864,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
 #endif
-    case kS390_DivFloat64:
+    case kS390_DivDouble:
       ASSEMBLE_FLOAT_BINOP_RC(fdiv);
       break;
     case kS390_Mod32:
@@ -806,37 +883,39 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       ASSEMBLE_MODULO(divdu, mulld);
       break;
 #endif
-    case kS390_ModFloat64:
+    case kS390_ModDouble:
       // TODO(bmeurer): We should really get rid of this special instruction,
       // and generate a CallAddress instruction instead.
       ASSEMBLE_FLOAT_MODULO();
       break;
-    case kS390_Neg32:
-    case kS390_Neg64:
+    case kS390_Neg:
       __ neg(i.OutputRegister(), i.InputRegister(0), LeaveOE, i.OutputRCBit());
       break;
-    case kS390_MaxFloat64:
+    case kS390_MaxDouble:
       ASSEMBLE_FLOAT_MAX(kScratchDoubleReg);
       break;
-    case kS390_MinFloat64:
+    case kS390_MinDouble:
       ASSEMBLE_FLOAT_MIN(kScratchDoubleReg);
       break;
-    case kS390_SqrtFloat64:
+    case kS390_AbsDouble:
+      ASSEMBLE_FLOAT_UNOP_RC(fabs);
+      break;
+    case kS390_SqrtDouble:
       ASSEMBLE_FLOAT_UNOP_RC(fsqrt);
       break;
-    case kS390_FloorFloat64:
+    case kS390_FloorDouble:
       ASSEMBLE_FLOAT_UNOP_RC(frim);
       break;
-    case kS390_CeilFloat64:
+    case kS390_CeilDouble:
       ASSEMBLE_FLOAT_UNOP_RC(frip);
       break;
-    case kS390_TruncateFloat64:
+    case kS390_TruncateDouble:
       ASSEMBLE_FLOAT_UNOP_RC(friz);
       break;
-    case kS390_RoundFloat64:
+    case kS390_RoundDouble:
       ASSEMBLE_FLOAT_UNOP_RC(frin);
       break;
-    case kS390_NegFloat64:
+    case kS390_NegDouble:
       ASSEMBLE_FLOAT_UNOP_RC(fneg);
       break;
     case kS390_Cntlz32:
@@ -851,7 +930,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       ASSEMBLE_COMPARE(cmp, cmpl);
       break;
 #endif
-    case kS390_CmpFloat64:
+    case kS390_CmpDouble:
       ASSEMBLE_FLOAT_COMPARE(fcmpu);
       break;
     case kS390_Tst32:
@@ -903,17 +982,17 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
 #endif
-    case kS390_Int32ToFloat64:
+    case kS390_Int32ToDouble:
       __ ConvertIntToDouble(i.InputRegister(0), i.OutputDoubleRegister());
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Uint32ToFloat64:
+    case kS390_Uint32ToDouble:
       __ ConvertUnsignedIntToDouble(i.InputRegister(0),
                                     i.OutputDoubleRegister());
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Float64ToInt32:
-    case kS390_Float64ToUint32:
+    case kS390_DoubleToInt32:
+    case kS390_DoubleToUint32:
       __ ConvertDoubleToInt64(i.InputDoubleRegister(0),
 #if !V8_TARGET_ARCH_S390X
                               kScratchReg,
@@ -921,31 +1000,31 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
                               i.OutputRegister(), kScratchDoubleReg);
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Float64ToFloat32:
+    case kS390_DoubleToFloat32:
       ASSEMBLE_FLOAT_UNOP_RC(frsp);
       break;
-    case kS390_Float32ToFloat64:
+    case kS390_Float32ToDouble:
       // Nothing to do.
       __ Move(i.OutputDoubleRegister(), i.InputDoubleRegister(0));
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Float64ExtractLowWord32:
+    case kS390_DoubleExtractLowWord32:
       __ MovDoubleLowToInt(i.OutputRegister(), i.InputDoubleRegister(0));
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Float64ExtractHighWord32:
+    case kS390_DoubleExtractHighWord32:
       __ MovDoubleHighToInt(i.OutputRegister(), i.InputDoubleRegister(0));
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Float64InsertLowWord32:
+    case kS390_DoubleInsertLowWord32:
       __ InsertDoubleLow(i.OutputDoubleRegister(), i.InputRegister(1), r0);
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Float64InsertHighWord32:
+    case kS390_DoubleInsertHighWord32:
       __ InsertDoubleHigh(i.OutputDoubleRegister(), i.InputRegister(1), r0);
       DCHECK_EQ(LeaveRC, i.OutputRCBit());
       break;
-    case kS390_Float64Construct:
+    case kS390_DoubleConstruct:
 #if V8_TARGET_ARCH_S390X
       __ MovInt64ComponentsToDouble(i.OutputDoubleRegister(),
                                     i.InputRegister(0), i.InputRegister(1), r0);
@@ -979,7 +1058,7 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
     case kS390_LoadFloat32:
       ASSEMBLE_LOAD_FLOAT(lfs, lfsx);
       break;
-    case kS390_LoadFloat64:
+    case kS390_LoadDouble:
       ASSEMBLE_LOAD_FLOAT(lfd, lfdx);
       break;
     case kS390_StoreWord8:
@@ -997,10 +1076,10 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       break;
 #endif
     case kS390_StoreFloat32:
-      ASSEMBLE_STORE_FLOAT(stfs, stfsx);
+      ASSEMBLE_STORE_FLOAT32();
       break;
-    case kS390_StoreFloat64:
-      ASSEMBLE_STORE_FLOAT(stfd, stfdx);
+    case kS390_StoreDouble:
+      ASSEMBLE_STORE_DOUBLE();
       break;
     case kS390_StoreWriteBarrier:
       ASSEMBLE_STORE_WRITE_BARRIER();
@@ -1037,16 +1116,16 @@ void CodeGenerator::AssembleArchInstruction(Instruction* instr) {
       ASSEMBLE_CHECKED_STORE_INTEGER(stw, stwx);
       break;
     case kCheckedStoreFloat32:
-      ASSEMBLE_CHECKED_STORE_FLOAT(stfs, stfsx);
+      ASSEMBLE_CHECKED_STORE_FLOAT32();
       break;
     case kCheckedStoreFloat64:
-      ASSEMBLE_CHECKED_STORE_FLOAT(stfd, stfdx);
+      ASSEMBLE_CHECKED_STORE_DOUBLE();
       break;
     default:
       UNREACHABLE();
       break;
   }
-}
+}  // NOLINT(readability/fn_size)
 
 
 // Assembles branches after an instruction.
@@ -1063,7 +1142,7 @@ void CodeGenerator::AssembleArchBranch(Instruction* instr, BranchInfo* branch) {
          (op == kS390_AddWithOverflow32 || op == kS390_SubWithOverflow32));
 
   Condition cond = FlagsConditionToCondition(condition);
-  if (op == kS390_CmpFloat64) {
+  if (op == kS390_CmpDouble) {
     // check for unordered if necessary
     if (cond == le) {
       __ bunordered(flabel, cr);
@@ -1089,7 +1168,7 @@ void CodeGenerator::AssembleArchBoolean(Instruction* instr,
   S390OperandConverter i(this, instr);
   Label done;
   ArchOpcode op = instr->arch_opcode();
-  bool check_unordered = (op == kS390_CmpFloat64);
+  bool check_unordered = (op == kS390_CmpDouble);
   CRegister cr = cr0;
 
   // Overflow checked for add/sub only.
@@ -1309,9 +1388,19 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
         case Constant::kExternalReference:
           __ mov(dst, Operand(src.ToExternalReference()));
           break;
-        case Constant::kHeapObject:
-          __ Move(dst, src.ToHeapObject());
+        case Constant::kHeapObject: {
+          Handle<HeapObject> src_object = src.ToHeapObject();
+          Heap::RootListIndex index;
+          int offset;
+          if (IsMaterializableFromFrame(src_object, &offset)) {
+            __ LoadP(dst, MemOperand(fp, offset));
+          } else if (IsMaterializableFromRoot(src_object, &index)) {
+            __ LoadRoot(dst, index);
+          } else {
+            __ Move(dst, src_object);
+          }
           break;
+        }
         case Constant::kRpoNumber:
           UNREACHABLE();  // TODO(dcarney): loading RPO constants on S390.
           break;
diff --git a/src/compiler/s390/instruction-codes-s390.h b/src/compiler/s390/instruction-codes-s390.h
index bb0a771..0450495 100644
--- a/src/compiler/s390/instruction-codes-s390.h
+++ b/src/compiler/s390/instruction-codes-s390.h
@@ -12,16 +12,11 @@ namespace compiler {
 // S390-specific opcodes that specify which assembly sequence to emit.
 // Most opcodes specify a single instruction.
 #define TARGET_ARCH_OPCODE_LIST(V) \
-  V(S390_And32)                     \
-  V(S390_And64)                     \
-  V(S390_AndComplement32)           \
-  V(S390_AndComplement64)           \
-  V(S390_Or32)                      \
-  V(S390_Or64)                      \
-  V(S390_OrComplement32)            \
-  V(S390_OrComplement64)            \
-  V(S390_Xor32)                     \
-  V(S390_Xor64)                     \
+  V(S390_And)                       \
+  V(S390_AndComplement)             \
+  V(S390_Or)                        \
+  V(S390_OrComplement)              \
+  V(S390_Xor)                       \
   V(S390_ShiftLeft32)               \
   V(S390_ShiftLeft64)               \
   V(S390_ShiftRight32)              \
@@ -30,49 +25,46 @@ namespace compiler {
   V(S390_ShiftRightAlg64)           \
   V(S390_RotRight32)                \
   V(S390_RotRight64)                \
-  V(S390_Not32)                     \
-  V(S390_Not64)                     \
+  V(S390_Not)                       \
   V(S390_RotLeftAndMask32)          \
   V(S390_RotLeftAndClear64)         \
   V(S390_RotLeftAndClearLeft64)     \
   V(S390_RotLeftAndClearRight64)    \
-  V(S390_Add32)                     \
+  V(S390_Add)                       \
   V(S390_AddWithOverflow32)         \
-  V(S390_Add64)                     \
-  V(S390_AddFloat64)                \
-  V(S390_Sub32)                     \
+  V(S390_AddDouble)                 \
+  V(S390_Sub)                       \
   V(S390_SubWithOverflow32)         \
-  V(S390_Sub64)                     \
-  V(S390_SubFloat64)                \
+  V(S390_SubDouble)                 \
   V(S390_Mul32)                     \
   V(S390_Mul64)                     \
   V(S390_MulHigh32)                 \
   V(S390_MulHighU32)                \
-  V(S390_MulFloat64)                \
+  V(S390_MulDouble)                 \
   V(S390_Div32)                     \
   V(S390_Div64)                     \
   V(S390_DivU32)                    \
   V(S390_DivU64)                    \
-  V(S390_DivFloat64)                \
+  V(S390_DivDouble)                 \
   V(S390_Mod32)                     \
   V(S390_Mod64)                     \
   V(S390_ModU32)                    \
   V(S390_ModU64)                    \
-  V(S390_ModFloat64)                \
-  V(S390_Neg32)                     \
-  V(S390_Neg64)                     \
-  V(S390_NegFloat64)                \
-  V(S390_SqrtFloat64)               \
-  V(S390_FloorFloat64)              \
-  V(S390_CeilFloat64)               \
-  V(S390_TruncateFloat64)           \
-  V(S390_RoundFloat64)              \
-  V(S390_MaxFloat64)                \
-  V(S390_MinFloat64)                \
+  V(S390_ModDouble)                 \
+  V(S390_Neg)                       \
+  V(S390_NegDouble)                 \
+  V(S390_SqrtDouble)                \
+  V(S390_FloorDouble)               \
+  V(S390_CeilDouble)                \
+  V(S390_TruncateDouble)            \
+  V(S390_RoundDouble)               \
+  V(S390_MaxDouble)                 \
+  V(S390_MinDouble)                 \
+  V(S390_AbsDouble)                 \
   V(S390_Cntlz32)                   \
   V(S390_Cmp32)                     \
   V(S390_Cmp64)                     \
-  V(S390_CmpFloat64)                \
+  V(S390_CmpDouble)                 \
   V(S390_Tst32)                     \
   V(S390_Tst64)                     \
   V(S390_Push)                      \
@@ -81,17 +73,17 @@ namespace compiler {
   V(S390_ExtendSignWord32)          \
   V(S390_Uint32ToUint64)            \
   V(S390_Int64ToInt32)              \
-  V(S390_Int32ToFloat64)            \
-  V(S390_Uint32ToFloat64)           \
-  V(S390_Float32ToFloat64)          \
-  V(S390_Float64ToInt32)            \
-  V(S390_Float64ToUint32)           \
-  V(S390_Float64ToFloat32)          \
-  V(S390_Float64ExtractLowWord32)   \
-  V(S390_Float64ExtractHighWord32)  \
-  V(S390_Float64InsertLowWord32)    \
-  V(S390_Float64InsertHighWord32)   \
-  V(S390_Float64Construct)          \
+  V(S390_Int32ToDouble)             \
+  V(S390_Uint32ToDouble)            \
+  V(S390_Float32ToDouble)           \
+  V(S390_DoubleToInt32)             \
+  V(S390_DoubleToUint32)            \
+  V(S390_DoubleToFloat32)           \
+  V(S390_DoubleExtractLowWord32)    \
+  V(S390_DoubleExtractHighWord32)   \
+  V(S390_DoubleInsertLowWord32)     \
+  V(S390_DoubleInsertHighWord32)    \
+  V(S390_DoubleConstruct)           \
   V(S390_LoadWordS8)                \
   V(S390_LoadWordU8)                \
   V(S390_LoadWordS16)               \
@@ -99,13 +91,13 @@ namespace compiler {
   V(S390_LoadWordS32)               \
   V(S390_LoadWord64)                \
   V(S390_LoadFloat32)               \
-  V(S390_LoadFloat64)               \
+  V(S390_LoadDouble)                \
   V(S390_StoreWord8)                \
   V(S390_StoreWord16)               \
   V(S390_StoreWord32)               \
   V(S390_StoreWord64)               \
   V(S390_StoreFloat32)              \
-  V(S390_StoreFloat64)              \
+  V(S390_StoreDouble)               \
   V(S390_StoreWriteBarrier)
 
 
diff --git a/src/compiler/s390/instruction-selector-s390.cc b/src/compiler/s390/instruction-selector-s390.cc
index ae4c97a..afe30d4 100644
--- a/src/compiler/s390/instruction-selector-s390.cc
+++ b/src/compiler/s390/instruction-selector-s390.cc
@@ -2,6 +2,7 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
+#include "src/base/adapters.h"
 #include "src/compiler/instruction-selector-impl.h"
 #include "src/compiler/node-matchers.h"
 #include "src/compiler/node-properties.h"
@@ -22,7 +23,7 @@ enum ImmediateMode {
 
 
 // Adds S390-specific methods for generating operands.
-class S390OperandGenerator FINAL : public OperandGenerator {
+class S390OperandGenerator final : public OperandGenerator {
  public:
   explicit S390OperandGenerator(InstructionSelector* selector)
       : OperandGenerator(selector) {}
@@ -67,25 +68,16 @@ class S390OperandGenerator FINAL : public OperandGenerator {
 };
 
 
-static void VisitRRFloat64(InstructionSelector* selector, ArchOpcode opcode,
-                           Node* node) {
-  S390OperandGenerator g(selector);
-  selector->Emit(opcode, g.DefineAsRegister(node),
-                 g.UseRegister(node->InputAt(0)));
-}
+namespace {
 
-
-static void VisitRRR(InstructionSelector* selector, Node* node,
-                     ArchOpcode opcode) {
+void VisitRR(InstructionSelector* selector, ArchOpcode opcode, Node* node) {
   S390OperandGenerator g(selector);
   selector->Emit(opcode, g.DefineAsRegister(node),
-                 g.UseRegister(node->InputAt(0)),
-                 g.UseRegister(node->InputAt(1)));
+                 g.UseRegister(node->InputAt(0)));
 }
 
 
-static void VisitRRRFloat64(InstructionSelector* selector, Node* node,
-                            ArchOpcode opcode) {
+void VisitRRR(InstructionSelector* selector, ArchOpcode opcode, Node* node) {
   S390OperandGenerator g(selector);
   selector->Emit(opcode, g.DefineAsRegister(node),
                  g.UseRegister(node->InputAt(0)),
@@ -93,8 +85,8 @@ static void VisitRRRFloat64(InstructionSelector* selector, Node* node,
 }
 
 
-static void VisitRRO(InstructionSelector* selector, Node* node,
-                     ArchOpcode opcode, ImmediateMode operand_mode) {
+void VisitRRO(InstructionSelector* selector, ArchOpcode opcode, Node* node,
+              ImmediateMode operand_mode) {
   S390OperandGenerator g(selector);
   selector->Emit(opcode, g.DefineAsRegister(node),
                  g.UseRegister(node->InputAt(0)),
@@ -104,9 +96,9 @@ static void VisitRRO(InstructionSelector* selector, Node* node,
 
 // Shared routine for multiple binary operations.
 template <typename Matcher>
-static void VisitBinop(InstructionSelector* selector, Node* node,
-                       InstructionCode opcode, ImmediateMode operand_mode,
-                       FlagsContinuation* cont) {
+void VisitBinop(InstructionSelector* selector, Node* node,
+                InstructionCode opcode, ImmediateMode operand_mode,
+                FlagsContinuation* cont) {
   S390OperandGenerator g(selector);
   Matcher m(node);
   InstructionOperand inputs[4];
@@ -139,12 +131,14 @@ static void VisitBinop(InstructionSelector* selector, Node* node,
 
 // Shared routine for multiple binary operations.
 template <typename Matcher>
-static void VisitBinop(InstructionSelector* selector, Node* node,
-                       ArchOpcode opcode, ImmediateMode operand_mode) {
+void VisitBinop(InstructionSelector* selector, Node* node, ArchOpcode opcode,
+                ImmediateMode operand_mode) {
   FlagsContinuation cont;
   VisitBinop<Matcher>(selector, node, opcode, operand_mode, &cont);
 }
 
+}  // namespace
+
 
 void InstructionSelector::VisitLoad(Node* node) {
   MachineType rep = RepresentationOf(OpParameter<LoadRepresentation>(node));
@@ -160,7 +154,7 @@ void InstructionSelector::VisitLoad(Node* node) {
       opcode = kS390_LoadFloat32;
       break;
     case kRepFloat64:
-      opcode = kS390_LoadFloat64;
+      opcode = kS390_LoadDouble;
       break;
     case kRepBit:  // Fall through.
     case kRepWord8:
@@ -230,7 +224,7 @@ void InstructionSelector::VisitStore(Node* node) {
       opcode = kS390_StoreFloat32;
       break;
     case kRepFloat64:
-      opcode = kS390_StoreFloat64;
+      opcode = kS390_StoreDouble;
       break;
     case kRepBit:  // Fall through.
     case kRepWord8:
@@ -348,17 +342,11 @@ static void VisitLogical(InstructionSelector* selector, Node* node, Matcher* m,
   // Map instruction to equivalent operation with inverted right input.
   ArchOpcode inv_opcode = opcode;
   switch (opcode) {
-    case kS390_And32:
-      inv_opcode = kS390_AndComplement32;
-      break;
-    case kS390_And64:
-      inv_opcode = kS390_AndComplement64;
-      break;
-    case kS390_Or32:
-      inv_opcode = kS390_OrComplement32;
+    case kS390_And:
+      inv_opcode = kS390_AndComplement;
       break;
-    case kS390_Or64:
-      inv_opcode = kS390_OrComplement64;
+    case kS390_Or:
+      inv_opcode = kS390_OrComplement;
       break;
     default:
       UNREACHABLE();
@@ -451,7 +439,7 @@ void InstructionSelector::VisitWord32And(Node* node) {
     }
   }
   VisitLogical<Int32BinopMatcher>(
-      this, node, &m, kS390_And32, CanCover(node, m.left().node()),
+      this, node, &m, kS390_And, CanCover(node, m.left().node()),
       CanCover(node, m.right().node()), kInt16Imm_Unsigned);
 }
 
@@ -508,7 +496,7 @@ void InstructionSelector::VisitWord64And(Node* node) {
     }
   }
   VisitLogical<Int64BinopMatcher>(
-      this, node, &m, kS390_And64, CanCover(node, m.left().node()),
+      this, node, &m, kS390_And, CanCover(node, m.left().node()),
       CanCover(node, m.right().node()), kInt16Imm_Unsigned);
 }
 #endif
@@ -517,7 +505,7 @@ void InstructionSelector::VisitWord64And(Node* node) {
 void InstructionSelector::VisitWord32Or(Node* node) {
   Int32BinopMatcher m(node);
   VisitLogical<Int32BinopMatcher>(
-      this, node, &m, kS390_Or32, CanCover(node, m.left().node()),
+      this, node, &m, kS390_Or, CanCover(node, m.left().node()),
       CanCover(node, m.right().node()), kInt16Imm_Unsigned);
 }
 
@@ -526,7 +514,7 @@ void InstructionSelector::VisitWord32Or(Node* node) {
 void InstructionSelector::VisitWord64Or(Node* node) {
   Int64BinopMatcher m(node);
   VisitLogical<Int64BinopMatcher>(
-      this, node, &m, kS390_Or64, CanCover(node, m.left().node()),
+      this, node, &m, kS390_Or, CanCover(node, m.left().node()),
       CanCover(node, m.right().node()), kInt16Imm_Unsigned);
 }
 #endif
@@ -536,9 +524,9 @@ void InstructionSelector::VisitWord32Xor(Node* node) {
   S390OperandGenerator g(this);
   Int32BinopMatcher m(node);
   if (m.right().Is(-1)) {
-    Emit(kS390_Not32, g.DefineAsRegister(node), g.UseRegister(m.left().node()));
+    Emit(kS390_Not, g.DefineAsRegister(node), g.UseRegister(m.left().node()));
   } else {
-    VisitBinop<Int32BinopMatcher>(this, node, kS390_Xor32, kInt16Imm_Unsigned);
+    VisitBinop<Int32BinopMatcher>(this, node, kS390_Xor, kInt16Imm_Unsigned);
   }
 }
 
@@ -548,9 +536,9 @@ void InstructionSelector::VisitWord64Xor(Node* node) {
   S390OperandGenerator g(this);
   Int64BinopMatcher m(node);
   if (m.right().Is(-1)) {
-    Emit(kS390_Not64, g.DefineAsRegister(node), g.UseRegister(m.left().node()));
+    Emit(kS390_Not, g.DefineAsRegister(node), g.UseRegister(m.left().node()));
   } else {
-    VisitBinop<Int64BinopMatcher>(this, node, kS390_Xor64, kInt16Imm_Unsigned);
+    VisitBinop<Int64BinopMatcher>(this, node, kS390_Xor, kInt16Imm_Unsigned);
   }
 }
 #endif
@@ -577,7 +565,7 @@ void InstructionSelector::VisitWord32Shl(Node* node) {
       }
     }
   }
-  VisitRRO(this, node, kS390_ShiftLeft32, kShift32Imm);
+  VisitRRO(this, kS390_ShiftLeft32, node, kShift32Imm);
 }
 
 
@@ -622,7 +610,7 @@ void InstructionSelector::VisitWord64Shl(Node* node) {
       }
     }
   }
-  VisitRRO(this, node, kS390_ShiftLeft64, kShift64Imm);
+  VisitRRO(this, kS390_ShiftLeft64, node, kShift64Imm);
 }
 #endif
 
@@ -649,7 +637,7 @@ void InstructionSelector::VisitWord32Shr(Node* node) {
       }
     }
   }
-  VisitRRO(this, node, kS390_ShiftRight32, kShift32Imm);
+  VisitRRO(this, kS390_ShiftRight32, node, kShift32Imm);
 }
 
 
@@ -690,7 +678,7 @@ void InstructionSelector::VisitWord64Shr(Node* node) {
       }
     }
   }
-  VisitRRO(this, node, kS390_ShiftRight64, kShift64Imm);
+  VisitRRO(this, kS390_ShiftRight64, node, kShift64Imm);
 }
 #endif
 
@@ -711,27 +699,27 @@ void InstructionSelector::VisitWord32Sar(Node* node) {
       return;
     }
   }
-  VisitRRO(this, node, kS390_ShiftRightAlg32, kShift32Imm);
+  VisitRRO(this, kS390_ShiftRightAlg32, node, kShift32Imm);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitWord64Sar(Node* node) {
-  VisitRRO(this, node, kS390_ShiftRightAlg64, kShift64Imm);
+  VisitRRO(this, kS390_ShiftRightAlg64, node, kShift64Imm);
 }
 #endif
 
 
 // TODO(mbrandy): Absorb logical-and into rlwinm?
 void InstructionSelector::VisitWord32Ror(Node* node) {
-  VisitRRO(this, node, kS390_RotRight32, kShift32Imm);
+  VisitRRO(this, kS390_RotRight32, node, kShift32Imm);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 // TODO(mbrandy): Absorb logical-and into rldic?
 void InstructionSelector::VisitWord64Ror(Node* node) {
-  VisitRRO(this, node, kS390_RotRight64, kShift64Imm);
+  VisitRRO(this, kS390_RotRight64, node, kShift64Imm);
 }
 #endif
 
@@ -743,13 +731,13 @@ void InstructionSelector::VisitWord32Clz(Node* node) {
 
 
 void InstructionSelector::VisitInt32Add(Node* node) {
-  VisitBinop<Int32BinopMatcher>(this, node, kS390_Add32, kInt16Imm);
+  VisitBinop<Int32BinopMatcher>(this, node, kS390_Add, kInt16Imm);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitInt64Add(Node* node) {
-  VisitBinop<Int64BinopMatcher>(this, node, kS390_Add64, kInt16Imm);
+  VisitBinop<Int64BinopMatcher>(this, node, kS390_Add, kInt16Imm);
 }
 #endif
 
@@ -758,9 +746,9 @@ void InstructionSelector::VisitInt32Sub(Node* node) {
   S390OperandGenerator g(this);
   Int32BinopMatcher m(node);
   if (m.left().Is(0)) {
-    Emit(kS390_Neg32, g.DefineAsRegister(node), g.UseRegister(m.right().node()));
+    Emit(kS390_Neg, g.DefineAsRegister(node), g.UseRegister(m.right().node()));
   } else {
-    VisitBinop<Int32BinopMatcher>(this, node, kS390_Sub32, kInt16Imm_Negate);
+    VisitBinop<Int32BinopMatcher>(this, node, kS390_Sub, kInt16Imm_Negate);
   }
 }
 
@@ -770,22 +758,22 @@ void InstructionSelector::VisitInt64Sub(Node* node) {
   S390OperandGenerator g(this);
   Int64BinopMatcher m(node);
   if (m.left().Is(0)) {
-    Emit(kS390_Neg64, g.DefineAsRegister(node), g.UseRegister(m.right().node()));
+    Emit(kS390_Neg, g.DefineAsRegister(node), g.UseRegister(m.right().node()));
   } else {
-    VisitBinop<Int64BinopMatcher>(this, node, kS390_Sub64, kInt16Imm_Negate);
+    VisitBinop<Int64BinopMatcher>(this, node, kS390_Sub, kInt16Imm_Negate);
   }
 }
 #endif
 
 
 void InstructionSelector::VisitInt32Mul(Node* node) {
-  VisitRRR(this, node, kS390_Mul32);
+  VisitRRR(this, kS390_Mul32, node);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitInt64Mul(Node* node) {
-  VisitRRR(this, node, kS390_Mul64);
+  VisitRRR(this, kS390_Mul64, node);
 }
 #endif
 
@@ -805,94 +793,82 @@ void InstructionSelector::VisitUint32MulHigh(Node* node) {
 
 
 void InstructionSelector::VisitInt32Div(Node* node) {
-  VisitRRR(this, node, kS390_Div32);
+  VisitRRR(this, kS390_Div32, node);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitInt64Div(Node* node) {
-  VisitRRR(this, node, kS390_Div64);
+  VisitRRR(this, kS390_Div64, node);
 }
 #endif
 
 
 void InstructionSelector::VisitUint32Div(Node* node) {
-  VisitRRR(this, node, kS390_DivU32);
+  VisitRRR(this, kS390_DivU32, node);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitUint64Div(Node* node) {
-  VisitRRR(this, node, kS390_DivU64);
+  VisitRRR(this, kS390_DivU64, node);
 }
 #endif
 
 
 void InstructionSelector::VisitInt32Mod(Node* node) {
-  VisitRRR(this, node, kS390_Mod32);
+  VisitRRR(this, kS390_Mod32, node);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitInt64Mod(Node* node) {
-  VisitRRR(this, node, kS390_Mod64);
+  VisitRRR(this, kS390_Mod64, node);
 }
 #endif
 
 
 void InstructionSelector::VisitUint32Mod(Node* node) {
-  VisitRRR(this, node, kS390_ModU32);
+  VisitRRR(this, kS390_ModU32, node);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitUint64Mod(Node* node) {
-  VisitRRR(this, node, kS390_ModU64);
+  VisitRRR(this, kS390_ModU64, node);
 }
 #endif
 
 
 void InstructionSelector::VisitChangeFloat32ToFloat64(Node* node) {
-  S390OperandGenerator g(this);
-  Emit(kS390_Float32ToFloat64, g.DefineAsRegister(node),
-       g.UseRegister(node->InputAt(0)));
+  VisitRR(this, kS390_Float32ToDouble, node);
 }
 
 
 void InstructionSelector::VisitChangeInt32ToFloat64(Node* node) {
-  S390OperandGenerator g(this);
-  Emit(kS390_Int32ToFloat64, g.DefineAsRegister(node),
-       g.UseRegister(node->InputAt(0)));
+  VisitRR(this, kS390_Int32ToDouble, node);
 }
 
 
 void InstructionSelector::VisitChangeUint32ToFloat64(Node* node) {
-  S390OperandGenerator g(this);
-  Emit(kS390_Uint32ToFloat64, g.DefineAsRegister(node),
-       g.UseRegister(node->InputAt(0)));
+  VisitRR(this, kS390_Uint32ToDouble, node);
 }
 
 
 void InstructionSelector::VisitChangeFloat64ToInt32(Node* node) {
-  S390OperandGenerator g(this);
-  Emit(kS390_Float64ToInt32, g.DefineAsRegister(node),
-       g.UseRegister(node->InputAt(0)));
+  VisitRR(this, kS390_DoubleToInt32, node);
 }
 
 
 void InstructionSelector::VisitChangeFloat64ToUint32(Node* node) {
-  S390OperandGenerator g(this);
-  Emit(kS390_Float64ToUint32, g.DefineAsRegister(node),
-       g.UseRegister(node->InputAt(0)));
+  VisitRR(this, kS390_DoubleToUint32, node);
 }
 
 
 #if V8_TARGET_ARCH_S390X
 void InstructionSelector::VisitChangeInt32ToInt64(Node* node) {
   // TODO(mbrandy): inspect input to see if nop is appropriate.
-  S390OperandGenerator g(this);
-  Emit(kS390_ExtendSignWord32, g.DefineAsRegister(node),
-       g.UseRegister(node->InputAt(0)));
+  VisitRR(this, kS390_ExtendSignWord32, node);
 }
 
 
@@ -907,7 +883,7 @@ void InstructionSelector::VisitChangeUint32ToUint64(Node* node) {
 
 void InstructionSelector::VisitTruncateFloat64ToFloat32(Node* node) {
   S390OperandGenerator g(this);
-  Emit(kS390_Float64ToFloat32, g.DefineAsRegister(node),
+  Emit(kS390_DoubleToFloat32, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
@@ -922,9 +898,26 @@ void InstructionSelector::VisitTruncateInt64ToInt32(Node* node) {
 #endif
 
 
+void InstructionSelector::VisitFloat32Add(Node* node) {
+  VisitRRR(this, kS390_AddDouble, node);
+}
+
+
 void InstructionSelector::VisitFloat64Add(Node* node) {
   // TODO(mbrandy): detect multiply-add
-  VisitRRRFloat64(this, node, kS390_AddFloat64);
+  VisitRRR(this, kS390_AddDouble, node);
+}
+
+
+void InstructionSelector::VisitFloat32Sub(Node* node) {
+  S390OperandGenerator g(this);
+  Float32BinopMatcher m(node);
+  if (m.left().IsMinusZero()) {
+    Emit(kS390_NegDouble, g.DefineAsRegister(node),
+         g.UseRegister(m.right().node()));
+    return;
+  }
+  VisitRRR(this, kS390_SubDouble, node);
 }
 
 
@@ -932,69 +925,109 @@ void InstructionSelector::VisitFloat64Sub(Node* node) {
   // TODO(mbrandy): detect multiply-subtract
   S390OperandGenerator g(this);
   Float64BinopMatcher m(node);
-  if (m.left().IsMinusZero() && m.right().IsFloat64RoundDown() &&
-      CanCover(m.node(), m.right().node())) {
-    if (m.right().InputAt(0)->opcode() == IrOpcode::kFloat64Sub &&
-        CanCover(m.right().node(), m.right().InputAt(0))) {
-      Float64BinopMatcher mright0(m.right().InputAt(0));
-      if (mright0.left().IsMinusZero()) {
-        // -floor(-x) = ceil(x)
-        Emit(kS390_CeilFloat64, g.DefineAsRegister(node),
-             g.UseRegister(mright0.right().node()));
-        return;
+  if (m.left().IsMinusZero()) {
+    if (m.right().IsFloat64RoundDown() &&
+        CanCover(m.node(), m.right().node())) {
+      if (m.right().InputAt(0)->opcode() == IrOpcode::kFloat64Sub &&
+          CanCover(m.right().node(), m.right().InputAt(0))) {
+        Float64BinopMatcher mright0(m.right().InputAt(0));
+        if (mright0.left().IsMinusZero()) {
+          // -floor(-x) = ceil(x)
+          Emit(kS390_CeilDouble, g.DefineAsRegister(node),
+               g.UseRegister(mright0.right().node()));
+          return;
+        }
       }
     }
+    Emit(kS390_NegDouble, g.DefineAsRegister(node),
+         g.UseRegister(m.right().node()));
+    return;
   }
-  VisitRRRFloat64(this, node, kS390_SubFloat64);
+  VisitRRR(this, kS390_SubDouble, node);
+}
+
+
+void InstructionSelector::VisitFloat32Mul(Node* node) {
+  VisitRRR(this, kS390_MulDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64Mul(Node* node) {
   // TODO(mbrandy): detect negate
-  VisitRRRFloat64(this, node, kS390_MulFloat64);
+  VisitRRR(this, kS390_MulDouble, node);
+}
+
+
+void InstructionSelector::VisitFloat32Div(Node* node) {
+  VisitRRR(this, kS390_DivDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64Div(Node* node) {
-  VisitRRRFloat64(this, node, kS390_DivFloat64);
+  VisitRRR(this, kS390_DivDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64Mod(Node* node) {
   S390OperandGenerator g(this);
-  Emit(kS390_ModFloat64, g.DefineAsFixed(node, d1),
+  Emit(kS390_ModDouble, g.DefineAsFixed(node, d1),
        g.UseFixed(node->InputAt(0), d1),
        g.UseFixed(node->InputAt(1), d2))->MarkAsCall();
 }
 
 
+void InstructionSelector::VisitFloat32Max(Node* node) {
+  VisitRRR(this, kS390_MaxDouble, node);
+}
+
+
 void InstructionSelector::VisitFloat64Max(Node* node) {
-  VisitRRRFloat64(this, node, kS390_MaxFloat64);
+  VisitRRR(this, kS390_MaxDouble, node);
+}
+
+
+void InstructionSelector::VisitFloat32Min(Node* node) {
+  VisitRRR(this, kS390_MinDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64Min(Node* node) {
-  VisitRRRFloat64(this, node, kS390_MinFloat64);
+  VisitRRR(this, kS390_MinDouble, node);
+}
+
+
+void InstructionSelector::VisitFloat32Abs(Node* node) {
+  VisitRR(this, kS390_AbsDouble, node);
+}
+
+
+void InstructionSelector::VisitFloat64Abs(Node* node) {
+  VisitRR(this, kS390_AbsDouble, node);
+}
+
+
+void InstructionSelector::VisitFloat32Sqrt(Node* node) {
+  VisitRR(this, kS390_SqrtDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64Sqrt(Node* node) {
-  VisitRRFloat64(this, kS390_SqrtFloat64, node);
+  VisitRR(this, kS390_SqrtDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64RoundDown(Node* node) {
-  VisitRRFloat64(this, kS390_FloorFloat64, node);
+  VisitRR(this, kS390_FloorDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64RoundTruncate(Node* node) {
-  VisitRRFloat64(this, kS390_TruncateFloat64, node);
+  VisitRR(this, kS390_TruncateDouble, node);
 }
 
 
 void InstructionSelector::VisitFloat64RoundTiesAway(Node* node) {
-  VisitRRFloat64(this, kS390_RoundFloat64, node);
+  VisitRR(this, kS390_RoundDouble, node);
 }
 
 
@@ -1037,10 +1070,12 @@ static bool CompareLogical(FlagsContinuation* cont) {
 }
 
 
+namespace {
+
 // Shared routine for multiple compare operations.
-static void VisitCompare(InstructionSelector* selector, InstructionCode opcode,
-                         InstructionOperand left, InstructionOperand right,
-                         FlagsContinuation* cont) {
+void VisitCompare(InstructionSelector* selector, InstructionCode opcode,
+                  InstructionOperand left, InstructionOperand right,
+                  FlagsContinuation* cont) {
   S390OperandGenerator g(selector);
   opcode = cont->Encode(opcode);
   if (cont->IsBranch()) {
@@ -1054,9 +1089,9 @@ static void VisitCompare(InstructionSelector* selector, InstructionCode opcode,
 
 
 // Shared routine for multiple word compare operations.
-static void VisitWordCompare(InstructionSelector* selector, Node* node,
-                             InstructionCode opcode, FlagsContinuation* cont,
-                             bool commutative, ImmediateMode immediate_mode) {
+void VisitWordCompare(InstructionSelector* selector, Node* node,
+                      InstructionCode opcode, FlagsContinuation* cont,
+                      bool commutative, ImmediateMode immediate_mode) {
   S390OperandGenerator g(selector);
   Node* left = node->InputAt(0);
   Node* right = node->InputAt(1);
@@ -1076,37 +1111,48 @@ static void VisitWordCompare(InstructionSelector* selector, Node* node,
 }
 
 
-static void VisitWord32Compare(InstructionSelector* selector, Node* node,
-                               FlagsContinuation* cont) {
+void VisitWord32Compare(InstructionSelector* selector, Node* node,
+                        FlagsContinuation* cont) {
   ImmediateMode mode = (CompareLogical(cont) ? kInt16Imm_Unsigned : kInt16Imm);
   VisitWordCompare(selector, node, kS390_Cmp32, cont, false, mode);
 }
 
 
 #if V8_TARGET_ARCH_S390X
-static void VisitWord64Compare(InstructionSelector* selector, Node* node,
-                               FlagsContinuation* cont) {
+void VisitWord64Compare(InstructionSelector* selector, Node* node,
+                        FlagsContinuation* cont) {
   ImmediateMode mode = (CompareLogical(cont) ? kInt16Imm_Unsigned : kInt16Imm);
   VisitWordCompare(selector, node, kS390_Cmp64, cont, false, mode);
 }
 #endif
 
 
-// Shared routine for multiple float compare operations.
-static void VisitFloat64Compare(InstructionSelector* selector, Node* node,
-                                FlagsContinuation* cont) {
+// Shared routine for multiple float32 compare operations.
+void VisitFloat32Compare(InstructionSelector* selector, Node* node,
+                         FlagsContinuation* cont) {
+  S390OperandGenerator g(selector);
+  Node* left = node->InputAt(0);
+  Node* right = node->InputAt(1);
+  VisitCompare(selector, kS390_CmpDouble, g.UseRegister(left),
+               g.UseRegister(right), cont);
+}
+
+
+// Shared routine for multiple float64 compare operations.
+void VisitFloat64Compare(InstructionSelector* selector, Node* node,
+                         FlagsContinuation* cont) {
   S390OperandGenerator g(selector);
   Node* left = node->InputAt(0);
   Node* right = node->InputAt(1);
-  VisitCompare(selector, kS390_CmpFloat64, g.UseRegister(left),
+  VisitCompare(selector, kS390_CmpDouble, g.UseRegister(left),
                g.UseRegister(right), cont);
 }
 
 
 // Shared routine for word comparisons against zero.
-static void VisitWordCompareZero(InstructionSelector* selector, Node* user,
-                                 Node* value, InstructionCode opcode,
-                                 FlagsContinuation* cont) {
+void VisitWordCompareZero(InstructionSelector* selector, Node* user,
+                          Node* value, InstructionCode opcode,
+                          FlagsContinuation* cont) {
   while (selector->CanCover(user, value)) {
     switch (value->opcode()) {
       case IrOpcode::kWord32Equal: {
@@ -1148,6 +1194,15 @@ static void VisitWordCompareZero(InstructionSelector* selector, Node* user,
         cont->OverwriteAndNegateIfEqual(kUnsignedLessThan);
         return VisitWord64Compare(selector, value, cont);
 #endif
+      case IrOpcode::kFloat32Equal:
+        cont->OverwriteAndNegateIfEqual(kEqual);
+        return VisitFloat32Compare(selector, value, cont);
+      case IrOpcode::kFloat32LessThan:
+        cont->OverwriteAndNegateIfEqual(kUnsignedLessThan);
+        return VisitFloat32Compare(selector, value, cont);
+      case IrOpcode::kFloat32LessThanOrEqual:
+        cont->OverwriteAndNegateIfEqual(kUnsignedLessThanOrEqual);
+        return VisitFloat32Compare(selector, value, cont);
       case IrOpcode::kFloat64Equal:
         cont->OverwriteAndNegateIfEqual(kEqual);
         return VisitFloat64Compare(selector, value, cont);
@@ -1228,19 +1283,21 @@ static void VisitWordCompareZero(InstructionSelector* selector, Node* user,
 }
 
 
-static void VisitWord32CompareZero(InstructionSelector* selector, Node* user,
-                                   Node* value, FlagsContinuation* cont) {
+void VisitWord32CompareZero(InstructionSelector* selector, Node* user,
+                            Node* value, FlagsContinuation* cont) {
   VisitWordCompareZero(selector, user, value, kS390_Cmp32, cont);
 }
 
 
 #if V8_TARGET_ARCH_S390X
-static void VisitWord64CompareZero(InstructionSelector* selector, Node* user,
-                                   Node* value, FlagsContinuation* cont) {
+void VisitWord64CompareZero(InstructionSelector* selector, Node* user,
+                            Node* value, FlagsContinuation* cont) {
   VisitWordCompareZero(selector, user, value, kS390_Cmp64, cont);
 }
 #endif
 
+}  // namespace
+
 
 void InstructionSelector::VisitBranch(Node* branch, BasicBlock* tbranch,
                                       BasicBlock* fbranch) {
@@ -1265,7 +1322,7 @@ void InstructionSelector::VisitSwitch(Node* node, const SwitchInfo& sw) {
     InstructionOperand index_operand = value_operand;
     if (sw.min_value) {
       index_operand = g.TempRegister();
-      Emit(kS390_Sub32, index_operand, value_operand,
+      Emit(kS390_Sub, index_operand, value_operand,
            g.TempImmediate(sw.min_value));
     }
     // Generate a table lookup.
@@ -1341,6 +1398,24 @@ void InstructionSelector::VisitUint64LessThan(Node* node) {
 #endif
 
 
+void InstructionSelector::VisitFloat32Equal(Node* node) {
+  FlagsContinuation cont(kEqual, node);
+  VisitFloat32Compare(this, node, &cont);
+}
+
+
+void InstructionSelector::VisitFloat32LessThan(Node* node) {
+  FlagsContinuation cont(kUnsignedLessThan, node);
+  VisitFloat32Compare(this, node, &cont);
+}
+
+
+void InstructionSelector::VisitFloat32LessThanOrEqual(Node* node) {
+  FlagsContinuation cont(kUnsignedLessThanOrEqual, node);
+  VisitFloat32Compare(this, node, &cont);
+}
+
+
 void InstructionSelector::VisitFloat64Equal(Node* node) {
   FlagsContinuation cont(kEqual, node);
   VisitFloat64Compare(this, node, &cont);
@@ -1361,9 +1436,9 @@ void InstructionSelector::VisitFloat64LessThanOrEqual(Node* node) {
 
 void InstructionSelector::VisitCall(Node* node, BasicBlock* handler) {
   S390OperandGenerator g(this);
-  const CallDescriptor* descriptor = OpParameter<CallDescriptor*>(node);
+  const CallDescriptor* descriptor = OpParameter<const CallDescriptor*>(node);
 
-  FrameStateDescriptor* frame_state_descriptor = NULL;
+  FrameStateDescriptor* frame_state_descriptor = nullptr;
   if (descriptor->NeedsFrameState()) {
     frame_state_descriptor =
         GetFrameStateDescriptor(node->InputAt(descriptor->InputCount()));
@@ -1379,14 +1454,13 @@ void InstructionSelector::VisitCall(Node* node, BasicBlock* handler) {
 
   // Push any stack arguments.
   // TODO(mbrandy): reverse order and use push only for first
-  for (auto i = buffer.pushed_nodes.rbegin(); i != buffer.pushed_nodes.rend();
-       i++) {
-    Emit(kS390_Push, g.NoOutput(), g.UseRegister(*i));
+  for (Node* node : base::Reversed(buffer.pushed_nodes)) {
+    Emit(kS390_Push, g.NoOutput(), g.UseRegister(node));
   }
 
   // Pass label of exception handler block.
   CallDescriptor::Flags flags = descriptor->flags();
-  if (handler != nullptr) {
+  if (handler) {
     flags |= CallDescriptor::kHasExceptionHandler;
     buffer.instruction_args.push_back(g.Label(handler));
   }
@@ -1408,25 +1482,108 @@ void InstructionSelector::VisitCall(Node* node, BasicBlock* handler) {
   opcode |= MiscField::encode(flags);
 
   // Emit the call instruction.
-  InstructionOperand* first_output =
-      buffer.outputs.size() > 0 ? &buffer.outputs.front() : NULL;
-  Instruction* call_instr =
-      Emit(opcode, buffer.outputs.size(), first_output,
-           buffer.instruction_args.size(), &buffer.instruction_args.front());
-  call_instr->MarkAsCall();
+  size_t const output_count = buffer.outputs.size();
+  auto* outputs = output_count ? &buffer.outputs.front() : nullptr;
+  Emit(opcode, output_count, outputs, buffer.instruction_args.size(),
+       &buffer.instruction_args.front())->MarkAsCall();
+}
+
+
+void InstructionSelector::VisitTailCall(Node* node) {
+  S390OperandGenerator g(this);
+  CallDescriptor const* descriptor = OpParameter<CallDescriptor const*>(node);
+  DCHECK_NE(0, descriptor->flags() & CallDescriptor::kSupportsTailCalls);
+  DCHECK_EQ(0, descriptor->flags() & CallDescriptor::kPatchableCallSite);
+  DCHECK_EQ(0, descriptor->flags() & CallDescriptor::kNeedsNopAfterCall);
+
+  // TODO(turbofan): Relax restriction for stack parameters.
+  if (descriptor->UsesOnlyRegisters() &&
+      descriptor->HasSameReturnLocationsAs(
+          linkage()->GetIncomingDescriptor())) {
+    CallBuffer buffer(zone(), descriptor, nullptr);
+
+    // Compute InstructionOperands for inputs and outputs.
+    // TODO(turbofan): on S390 it's probably better to use the code object in a
+    // register if there are multiple uses of it. Improve constant pool and the
+    // heuristics in the register allocator for where to emit constants.
+    InitializeCallBuffer(node, &buffer, true, false);
+
+    DCHECK_EQ(0u, buffer.pushed_nodes.size());
+
+    // Select the appropriate opcode based on the call type.
+    InstructionCode opcode;
+    switch (descriptor->kind()) {
+      case CallDescriptor::kCallCodeObject:
+        opcode = kArchTailCallCodeObject;
+        break;
+      case CallDescriptor::kCallJSFunction:
+        opcode = kArchTailCallJSFunction;
+        break;
+      default:
+        UNREACHABLE();
+        return;
+    }
+    opcode |= MiscField::encode(descriptor->flags());
+
+    // Emit the tailcall instruction.
+    Emit(opcode, 0, nullptr, buffer.instruction_args.size(),
+         &buffer.instruction_args.front());
+  } else {
+    FrameStateDescriptor* frame_state_descriptor = nullptr;
+    if (descriptor->NeedsFrameState()) {
+      frame_state_descriptor =
+          GetFrameStateDescriptor(node->InputAt(descriptor->InputCount()));
+    }
+
+    CallBuffer buffer(zone(), descriptor, frame_state_descriptor);
+
+    // Compute InstructionOperands for inputs and outputs.
+    // TODO(turbofan): on S390 it's probably better to use the code object in a
+    // register if there are multiple uses of it. Improve constant pool and the
+    // heuristics in the register allocator for where to emit constants.
+    InitializeCallBuffer(node, &buffer, true, false);
+
+    // Push any stack arguments.
+    for (Node* node : base::Reversed(buffer.pushed_nodes)) {
+      Emit(kS390_Push, g.NoOutput(), g.UseRegister(node));
+    }
+
+    // Select the appropriate opcode based on the call type.
+    InstructionCode opcode;
+    switch (descriptor->kind()) {
+      case CallDescriptor::kCallCodeObject: {
+        opcode = kArchCallCodeObject;
+        break;
+      }
+      case CallDescriptor::kCallJSFunction:
+        opcode = kArchCallJSFunction;
+        break;
+      default:
+        UNREACHABLE();
+        return;
+    }
+    opcode |= MiscField::encode(descriptor->flags());
+
+    // Emit the call instruction.
+    size_t const output_count = buffer.outputs.size();
+    auto* outputs = output_count ? &buffer.outputs.front() : nullptr;
+    Emit(opcode, output_count, outputs, buffer.instruction_args.size(),
+         &buffer.instruction_args.front())->MarkAsCall();
+    Emit(kArchRet, 0, nullptr, output_count, outputs);
+  }
 }
 
 
 void InstructionSelector::VisitFloat64ExtractLowWord32(Node* node) {
   S390OperandGenerator g(this);
-  Emit(kS390_Float64ExtractLowWord32, g.DefineAsRegister(node),
+  Emit(kS390_DoubleExtractLowWord32, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
 
 void InstructionSelector::VisitFloat64ExtractHighWord32(Node* node) {
   S390OperandGenerator g(this);
-  Emit(kS390_Float64ExtractHighWord32, g.DefineAsRegister(node),
+  Emit(kS390_DoubleExtractHighWord32, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
@@ -1438,11 +1595,11 @@ void InstructionSelector::VisitFloat64InsertLowWord32(Node* node) {
   if (left->opcode() == IrOpcode::kFloat64InsertHighWord32 &&
       CanCover(node, left)) {
     left = left->InputAt(1);
-    Emit(kS390_Float64Construct, g.DefineAsRegister(node), g.UseRegister(left),
+    Emit(kS390_DoubleConstruct, g.DefineAsRegister(node), g.UseRegister(left),
          g.UseRegister(right));
     return;
   }
-  Emit(kS390_Float64InsertLowWord32, g.DefineSameAsFirst(node),
+  Emit(kS390_DoubleInsertLowWord32, g.DefineSameAsFirst(node),
        g.UseRegister(left), g.UseRegister(right));
 }
 
@@ -1454,11 +1611,11 @@ void InstructionSelector::VisitFloat64InsertHighWord32(Node* node) {
   if (left->opcode() == IrOpcode::kFloat64InsertLowWord32 &&
       CanCover(node, left)) {
     left = left->InputAt(1);
-    Emit(kS390_Float64Construct, g.DefineAsRegister(node), g.UseRegister(right),
+    Emit(kS390_DoubleConstruct, g.DefineAsRegister(node), g.UseRegister(right),
          g.UseRegister(left));
     return;
   }
-  Emit(kS390_Float64InsertHighWord32, g.DefineSameAsFirst(node),
+  Emit(kS390_DoubleInsertHighWord32, g.DefineSameAsFirst(node),
        g.UseRegister(left), g.UseRegister(right));
 }
 
@@ -1466,7 +1623,9 @@ void InstructionSelector::VisitFloat64InsertHighWord32(Node* node) {
 // static
 MachineOperatorBuilder::Flags
 InstructionSelector::SupportedMachineOperatorFlags() {
-  return MachineOperatorBuilder::kFloat64Max |
+  return MachineOperatorBuilder::kFloat32Max |
+         MachineOperatorBuilder::kFloat32Min |
+         MachineOperatorBuilder::kFloat64Max |
          MachineOperatorBuilder::kFloat64Min |
          MachineOperatorBuilder::kFloat64RoundDown |
          MachineOperatorBuilder::kFloat64RoundTruncate |
